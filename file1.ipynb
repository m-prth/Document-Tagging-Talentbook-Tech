{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9a49d3a259926101afb46326be26cd11fa432d37c9ff2a03f17c25488b92116e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 1. Importing libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## 2. Getting all the documents from the directory to a dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_docs = []\n",
    "for i in range(0,80):\n",
    "    filepath = str('Train_docs\\case_'+str(i)+'_statement.txt')\n",
    "    with open(filepath) as f:\n",
    "        s = f.read()\n",
    "        s = re.sub(r\"[\\d+.\\n]\",\"\",s)\n",
    "        list_of_docs.append(s)\n",
    "\n",
    "df = pd.DataFrame(list_of_docs,columns=['docs'])\n"
   ]
  },
  {
   "source": [
    "## 3. Similarly, getting all the tags from the directory to the same dataframe "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 docs  \\\n",
       "0   Kurian Joseph, J Leave granted in Special Leav...   \n",
       "1   Abhay Manohar Sapre, J Delay in filing special...   \n",
       "2   Pinaki Chandra Ghose, J This criminal appeal, ...   \n",
       "3    This matter is placed before us as a Bench of...   \n",
       "4    We have heard learned Counsel for the parties...   \n",
       "..                                                ...   \n",
       "75   This is tenant's appeal by special leave Thou...   \n",
       "76  SB Sinha, J The primal question involved in th...   \n",
       "77  R Banumathi, J Leave granted This appeal by sp...   \n",
       "78  Dipak Misra, J Despite completion of a decade ...   \n",
       "79  HK Sema, J Four appellants - Anthony D'Souza, ...   \n",
       "\n",
       "                                                 tags  \n",
       "0   Absence, Access, Accident, Account, Acquisitio...  \n",
       "1                                     Cause of Action  \n",
       "2   Abetment, Abetment of Suicide, Absconding, Acc...  \n",
       "3   Decision, Exemption, Exemption Notification, I...  \n",
       "4   Child Labour, Compensation, Fundamental Right,...  \n",
       "..                                                ...  \n",
       "75  Absence, Appeal, Appellate Court, Bona Fide, B...  \n",
       "76  Administration of Justice, Admiralty Jurisdict...  \n",
       "77                                     Absorption, Ad  \n",
       "78  Appreciation of Evidence, Assault, Autopsy, Br...  \n",
       "79  Amicus Curiae, Circumstantial Evidence, Eye Wi...  \n",
       "\n",
       "[80 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>docs</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kurian Joseph, J Leave granted in Special Leav...</td>\n      <td>Absence, Access, Accident, Account, Acquisitio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abhay Manohar Sapre, J Delay in filing special...</td>\n      <td>Cause of Action</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pinaki Chandra Ghose, J This criminal appeal, ...</td>\n      <td>Abetment, Abetment of Suicide, Absconding, Acc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This matter is placed before us as a Bench of...</td>\n      <td>Decision, Exemption, Exemption Notification, I...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We have heard learned Counsel for the parties...</td>\n      <td>Child Labour, Compensation, Fundamental Right,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>This is tenant's appeal by special leave Thou...</td>\n      <td>Absence, Appeal, Appellate Court, Bona Fide, B...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>SB Sinha, J The primal question involved in th...</td>\n      <td>Administration of Justice, Admiralty Jurisdict...</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>R Banumathi, J Leave granted This appeal by sp...</td>\n      <td>Absorption, Ad</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Dipak Misra, J Despite completion of a decade ...</td>\n      <td>Appreciation of Evidence, Assault, Autopsy, Br...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>HK Sema, J Four appellants - Anthony D'Souza, ...</td>\n      <td>Amicus Curiae, Circumstantial Evidence, Eye Wi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "list_of_tags = []\n",
    "\n",
    "for j in range(0,80):\n",
    "    path = str('Train_tags\\case'+str(j)+'.txt')\n",
    "    with open(path) as f2:\n",
    "        for line in f2:\n",
    "            list_of_tags.append(line)\n",
    "    \n",
    "df['tags'] = list_of_tags\n",
    "df\n"
   ]
  },
  {
   "source": [
    "## 3. Splitting the tags into columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df['tags'])):\n",
    "    df['tags'][i] = list(df['tags'][i].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "type(df['tags'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "y = list()\n",
    "for i in range(0,len(df['tags'])):\n",
    "    y.append(df['tags'][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [item for sublist in y for item in sublist]"
   ]
  },
  {
   "source": [
    "### Used multilabel binarizer to convert all the tags to columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('tags')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index))"
   ]
  },
  {
   "source": [
    "## 4. Used lemmatization on the documents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "for i in range(len(df['docs'])):\n",
    "    words=nltk.word_tokenize(df['docs'][i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    df['docs'][i]=' '.join(words)"
   ]
  },
  {
   "source": [
    "## Vectorized the documents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "words = set(words)\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer=tokenizer_porter, vocabulary=words)\n",
    "X = vect.transform(df['docs']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}